{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo existe en el directorio.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Nombre del archivo Python\n",
    "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "# Ruta del archivo ZIP\n",
    "archivo_zip = 'tweets.json.zip'\n",
    "\n",
    "# Validamos si el archivo se encuentra en el directorio\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(\"El archivo existe en el directorio.\")\n",
    "else:\n",
    "    print(\"El archivo no existe en el directorio.\")\n",
    "    \n",
    "    # Descomprimir el archivo ZIP en el mismo directorio\n",
    "    with zipfile.ZipFile(archivo_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.dirname(archivo_zip))\n",
    "    print(\"Archivo descomprimido con éxito.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 Memoria Optimizada: El siguiente código, entrega las 10 fechas donde hay más tweets y con su usuario que más cantidad de tweet realizó optimizando la memoria. \n",
    "\n",
    "A diferencia del código siguiente (Q1_TIME), este código lo que hace es procesar el archivo json línea por línea. Esto hace que no carguemos todo el archivo al mismo tiempo, consumiendo más memoria. Ademas, la práctica dice que pandas es una excelente forma de manejar grandes conjunto de datos, sin embargo, algunas operaciones consumen mucha memoria. Dado lo anterior, se procedió a utilizar la la clase defaultdict que permite contabilizar mientras el archivo se procesa línea por línea. Por último, se podía crear un bucle, pero la función heapq.nlargest permite hacer una busqueda de los valores más grandes de forma eficiente, ya que un bucle tendría que iterar varias veces sobre un mismo conjunto de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio del proceso\n",
      "[('2021-02-12', 'RanbirS00614606'), ('2021-02-13', 'MaanDee08215437'), ('2021-02-17', 'RaaJVinderkaur'), ('2021-02-16', 'jot__b'), ('2021-02-14', 'rebelpacifist'), ('2021-02-18', 'neetuanjle_nitu'), ('2021-02-15', 'jot__b'), ('2021-02-20', 'MangalJ23056160'), ('2021-02-23', 'Surrypuria'), ('2021-02-19', 'Preetm91')]\n",
      "Tiempo de ejecución: 3.7404837608337402\n"
     ]
    }
   ],
   "source": [
    "#Importamos la funcion de archivo python en el mismo directorio\n",
    "from q1_memory import q1_memory\n",
    "\n",
    "#Inicio del marcador para medir tiempo\n",
    "initial_time = time()\n",
    "\n",
    "#Guardamos el resultado\n",
    "resultado_q1_memory = q1_memory(file_path)\n",
    "\n",
    "#Imprimimos\n",
    "print(resultado_q1_memory)\n",
    "print(f\"Tiempo de ejecución: {time() - initial_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 Tiempo Optimizado: El siguiente código, entrega las 10 fechas donde hay más tweets y con su usuario que más cantidad de tweet realizó optimizando el tiempo de ejecución.\n",
    "\n",
    "La diferencia en tiempo con respecto al código anterior (optimizado por memoria) es mínima, sin embargo, la diferencia radica en el conteo de apariciones en los datos. En vez de usar defaultdict, utilizamos un diccionario anidado. Además, en el procesamiento del archivo se eliminaron redundancias dentro del bucle y se determinó que usando setdefault podiamos reducir levemente el tiempo de ejecución debido a su capacidad de busqueda y asignación en una única operación para un diccionario.\n",
    "\n",
    "Realmente es dificil que pudieramos llegar a un tiempo mínimo drastico en comparación al anterior, debido a que la memoria y el tiempo son variables que la mayor parte de las veces mejoran directamente proporcional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio del proceso\n",
      "[('2021-02-12', 'RanbirS00614606'), ('2021-02-13', 'MaanDee08215437'), ('2021-02-17', 'RaaJVinderkaur'), ('2021-02-16', 'jot__b'), ('2021-02-14', 'rebelpacifist'), ('2021-02-18', 'neetuanjle_nitu'), ('2021-02-15', 'jot__b'), ('2021-02-20', 'MangalJ23056160'), ('2021-02-23', 'Surrypuria'), ('2021-02-19', 'Preetm91')]\n",
      "Tiempo de ejecución: 3.683811664581299\n"
     ]
    }
   ],
   "source": [
    "#Importamos la funcion de archivo python en el mismo directorio\n",
    "from q1_time import q1_time\n",
    "\n",
    "#Inicio del marcador para medir tiempo\n",
    "initial_time = time()\n",
    "\n",
    "#Guardamos el resultado\n",
    "resultado_q1_time = q1_time(file_path)\n",
    "\n",
    "#Imprimimos\n",
    "print(resultado_q1_time)\n",
    "print(f\"Tiempo de ejecución: {time() - initial_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
